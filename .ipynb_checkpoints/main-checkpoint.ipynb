{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils  \n",
    "from node2vec import Node2Vec  # NODE2VEC EMBEDDINGS \n",
    "import classifier as clf  # VERTEX CLASSIFIER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPIEGA PERCHE' RIMUOVIAMO LA FEATURE 10 , AGGIUNGI ANCHE IMMAGINI CHE TROVI NELLA CARTELLA IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATA\n",
    "vertices_train, vertices_test = utils.build_vertices()\n",
    "\n",
    "X_train_df = utils.build_dataframe(vertices_train, \"feature\")\n",
    "X_train_df = X_train_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "X_test_df = utils.build_dataframe(vertices_test, \"feature\")\n",
    "X_test_df = X_test_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "labels_df = utils.build_dataframe(vertices_train, \"label\", preserve_int_col_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING NUMPY MATRICES \n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "labels = labels_df.values\n",
    "\n",
    "\n",
    "# MASK FOR TRAIN/TEST\n",
    "train_idx = range(X_train.shape[0])\n",
    "test_idx = range(X_train.shape[0],X.shape[0])\n",
    "\n",
    "# BUILDING THE GRAPH\n",
    "G = utils.build_graph()\n",
    "G = G.to_directed()  # CONSIDERING THE GRAPH AS UNDIRECTED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INTRODUZIONE ALL'APPROCCIO DI  NODE2VEC , MOTIVAZIONI.. ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 56944/56944 [10:56<00:00, 86.75it/s] \n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [04:35<00:00, 29.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# GENERATING WALKS OVER THE GRAPH\n",
    "node2vec = Node2Vec(G, dimensions=128, walk_length=12, num_walks=10, p=1, q=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTO SUL MODELLO SKIP-GRAM E SULLA SCELTA DELLA WINDOW (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# FITTING THE SKIP-GRAM MODEL\n",
    "skipgram = node2vec.fit(window=8)\n",
    "\n",
    "\n",
    "#  SAVING OUR EMBEDDINGS\n",
    "embedding_n2v = skipgram[skipgram.wv.vocab]   \n",
    "np.save('./embedding/embedding_n2v.npy', embedding_n2v)  # SAVING AS  A .NPY FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPIEGA CHE CONCATENIAMO FEATURES CON EMBEDDING PER CLASSIFICARE, ACCENNO SULLA TRAIN ACCURACY (?), ACCENNO AL FATTO CHE NEL CLASSIFIER BILANCIAMO I PESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.438\n",
      "\tAccuracy, exact matches: 0.000\n",
      "\tMacro F1 Score: 0.439\n",
      "\tMicro F1 Score: 0.470\n"
     ]
    }
   ],
   "source": [
    "# X MATRIX FOR CLASSIFICATION\n",
    "train_embedding_n2v = embedding_n2v[train_idx]  # EXTRACTING TRAINING SET EMBEDDINGS\n",
    "test_embedding_n2v = embedding_n2v[test_idx]  #  EXTRACTING TEST SET EMBEDDING\n",
    "X_train_n2v = np.concatenate((X_train, train_embedding_n2v), axis=1)  #  FEATURES + EMBEDDING\n",
    "X_test_n2v = np.concatenate((X_test, test_embedding_n2v), axis=1)  # FEATURES + EMBEDDINGS\n",
    "\n",
    "\n",
    "#  TESTING VALIDATION ACCURACY\n",
    "#clf.validation_accuracy(X_train_n2v, labels)\n",
    "\n",
    "#  TESTING TRAIN ACCURACY\n",
    "node2vec_model = clf.fit_model(X_train_n2v, labels)  # RETURNS TRAINED MODEL AND TRAIN ACCURACY\n",
    "\n",
    "\n",
    "#  MAKING PREDICTIONS\n",
    "node2vec_pred = node2vec_model.predict_proba(X_test_n2v) > 0.4  # EVALUATING PREDICTIONS\n",
    "utils.get_results('./results/node2vec_pred.csv',node2vec_pred, X_test_df)  # SAVING RESULTS IN A .CSV FOR KAGGLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTO SUI RISULTATI OTTENUTI CON NODE2VEC, !!INTRODUZIONE AL PROSSIMO APPROCCIO( GCN ) \n",
    ", SBIZZARRISCITI..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gcn.model import GCN \n",
    "from train  import train_model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETRO  LAMDA PER GLI AUTOANELLI , SPIEGA COME VIENE CREATA LA MATRICE ( DAI UN OCCHIO ALLA FUNZIONE IN UTILS.PY ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING ADJ MATRIX FOR GCN\n",
    "A = utils.adjacency_matrix_GCN(G, 1)  \n",
    "\n",
    "\n",
    "# DEFINING OUR PARAMETERS\n",
    "n_features = X.shape[1]\n",
    "n_classes = labels.shape[1]\n",
    "n_hidden = 32  #  NUMBER OF HIDDEN PARAMETERS IN OUR NET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI VIENE CREATO E ALLENATO IL MODELLO..MAGARI UN BREVE ACCENNO ALLA STUTTURA ( 2 LAYER, HIDDEN PARAMETERS,DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:20<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# CREATING AND TRAINING OUR MODEL\n",
    "\n",
    "gcn_model = GCN(n_features, n_hidden, n_classes, dropout=0.5)\n",
    "embedding_gcn = train_model(gcn_model, X, A, labels, train_idx, epochs=50, lr=0.005, wd=5e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.710\n",
      "\tAccuracy, exact matches: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMacro F1 Score: 0.195\n",
      "\tMicro F1 Score: 0.506\n"
     ]
    }
   ],
   "source": [
    "#  EXTRACTING EMBEDDINGS \n",
    "train_embedding_gcn = embedding_gcn[train_idx]\n",
    "test_embedding_gcn = embedding_gcn[test_idx]\n",
    "\n",
    "\n",
    "#  TESTING TRAIN ACCURACY (SIGMOID TRESHOLD SET AT 0.4 )\n",
    "gcn_train_pred = torch.sigmoid(train_embedding_gcn).detach().numpy() > 0.4 \n",
    "utils.get_score(gcn_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_gcn.npy', embedding_gcn.detach().numpy())  # .NPY FILE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTO SUI RISULTATI OTTENUTI ( TRAINING ACCURACY ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "gcn_test_pred = torch.sigmoid(test_embedding_gcn).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "gcn_test_pred = utils.a_third_law(labels,gcn_test_pred) # 0.475 accuracy\n",
    "utils.get_results('./results/gcn_pred.csv',gcn_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONI FINALI SULLA GCN ( ACCURACY PRATICAMENTE UGUALE A NODE2VEC SE NON INFERIORE ) ( LE FEATURE NON SERVONO A NULLA??) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASSIAMO AL PROSSIMO APPROCCIO.. SAGE ( SBIZZARRISCITI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.model import SAGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STRUTTURA DEL MODELLO UGUALE A GCN ( 2LAYER , HIDDEN PARAMETERS..) SCRIVI QUELLO CHE PREFERISCI.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:31<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.306\n",
      "\tAccuracy, exact matches: 0.000\n",
      "\tMacro F1 Score: 0.445\n",
      "\tMicro F1 Score: 0.468\n"
     ]
    }
   ],
   "source": [
    "#  CREATING THE MODEL\n",
    "edge_list = torch.LongTensor(utils.edge_list_SAGE())  # list of all the edges\n",
    "sage_model = SAGE(n_features, n_hidden, n_classes, 0.5)\n",
    "\n",
    "\n",
    "#  TRAINING THE MODEL \n",
    "embedding_sage = train_model(sage_model, X, edge_list, labels, train_idx, epochs=25, lr=0.1,wd=5e-3)\n",
    "sage_train_pred = torch.sigmoid(embedding_sage[train_idx]).detach().numpy() > 0.5# TRESHOLD ON SIGMOID PROBABILITIES\n",
    "sage_train_pred = utils.a_third_law(labels,sage_test_pred)\n",
    "utils.get_score(sage_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_sage.npy', embedding_sage.detach().numpy())  # .NPY FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "sage_test_pred = torch.sigmoid(embedding_sage[test_idx]).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "sage_test_pred = utils.a_third_law(labels,sage_test_pred) # BEST SAGE 0.477\n",
    "utils.get_results('./results/sage_test_pred.csv',sage_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONI RAGGIUNTE SU SAGE.. ( NODE2VEC-GCN-SAGE TUTTI CIRCA LA  STESSA ACCURACY CIRCA 0.44/0.45/0.46 SUL TEST ) INIZIAMO A SOSPETTARE QUALCOSA(??) \n",
    "PROVIAMO A GIOCARE UN PO CON CONCATENAZIONE DEGLI EMBEDDING E PCA (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=16.7min\n",
      "[CV] ................................................. , total=17.4min\n",
      "[CV] ................................................. , total=17.5min\n",
      "[CV] ................................................. , total=17.6min\n",
      "[CV] ................................................. , total=17.6min\n",
      "[CV] ................................................. , total=17.7min\n",
      "[CV] ................................................. , total=17.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done   7 out of  10 | elapsed: 17.8min remaining:  7.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=17.8min\n",
      "[CV] ................................................. , total=17.8min\n",
      "[CV] ................................................. , total=17.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done  10 out of  10 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crossvalidation Micro-F1: 0.425\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate((embedding_n2v,embedding_sage),axis=1)  # N2V EMBEDDING concatenated SAGE EMBEDDING\n",
    "clf.validation_accuracy(Y[train_idx],labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RISULTATI UN PO DELUDENTI ( 0.425 DI MICRO ) PER LA CROSS VALIDATION (SAGE+N2V) CI ASPETTAVAMO DI MEGLIO... VALE LO STESSO PER GCN+N2V ( OMETTO PER BREVITA').\n",
    "\n",
    "PROVIAMO ORA CON UNA PCA SULLA CONCATENAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0.9977764\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 4.0min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done   7 out of  10 | elapsed:  4.1min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done  10 out of  10 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crossvalidation Micro-F1: 0.427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 64)\n",
    "Y_pca = pca.fit_transform(Y)  #  250 --> 64\n",
    "print('Explained variance: ',np.sum(pca.explained_variance_ratio_))  #  GOOD EXPLAINED VARIANCE\n",
    "clf.validation_accuracy(Y_pca[train_idx],labels)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTRO RISULTATO ABBASTANZA DELUDENTE.. PROVA A COMMENTARE TU ( NON C'E' VERSO DI MIGLIORARLA STA ACCURACY )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASSIAMO ORA ALLA NOSTRA ULTIMA SPERANZA.. GAT ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gat.ppi import PPI\n",
    "from gat.model import GAT\n",
    "from gat.train import train,test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOADING DATASETS \n",
    "train_dataset = PPI('./gat',split='train')\n",
    "test_dataset = PPI('./gat',split='test')\n",
    "valid_dataset = PPI('./gat',split='valid')  #  LET'S KEEP SOME TRAINING SAMPLES FOR VALIDATION..\n",
    "\n",
    "\n",
    "#  BATCH TRAINING.. \n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIZIONE DEL MODELLO GAT USATO DA NOI.. FAI RIFERIMENTO AL PAPER OPPURE AL FILE MODEL.PY IN /GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BUILDING AND TRAINING OUR MODEL\n",
    "model = GAT(n_features,n_classes)\n",
    "for epoch in range(1, 30):\n",
    "    loss = train(model,train_loader) \n",
    "    acc = test(model,valid_loader) \n",
    "    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "for data in test_loader:\n",
    "    out = model(data.x,data.edge_index)\n",
    "    \n",
    "pred = out.float().cpu() > 0\n",
    "pred = utils.a_third_law(labels,pred)\n",
    "\n",
    "utils.get_results('./results/gat_pred.csv',pred, X_test_df)  # SAVING RESULTS IN A .CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
