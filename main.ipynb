{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOMAIN OF THE DATA\n",
    "<br>\n",
    " PPI network can be represented as a graph with a total of $\\space n = 56944 \\space$ nodes ($\\space n_{train} = 44906 \\space$ in the training set and $\\space n_{test} = 12038 \\space$ in the test set) \n",
    " where each node can be identified with a specific protein. \n",
    " Furthermore each node is characterized with a <b>really sparse</b> binary features \n",
    " vector $\\space x\\in \\{0,1\\}^{50} \\space$ and a fixed number of undirected edges that connect each node to the others. \n",
    "\n",
    "In addition to the features we have the labels  of the training set ( a vector $l\\in \\{0,1\\}^{122}$)\n",
    "and our goal is to predict the labels of the test set with the best accuracy (F1 score will be evaluated). \n",
    "These are the data distributions: \n",
    "\n",
    "<div>\n",
    "<img src=\"./images/Training_set_features.png\" height=280 width=280>\n",
    "<img src=\"./images/Training_set_feature_elements.png\" height=280 width=280>\n",
    "<img src=\"./images/test_set_features.png\" height=280 width=280>\n",
    "</div>\n",
    "\n",
    "<div>\n",
    "<img src=\"./images/Test_set_feature_elements.png\" height=280 width=280>\n",
    "<img src=\"./images/labels.png\" height=280 width=280>\n",
    "<img src=\"./images/label_component.png\" height=280 width=280>\n",
    "</div>\n",
    "\n",
    "'Feature10' ( which corresponds to the third element in the plot ) is costant to zero in each sample of the dataset,\n",
    "we delete it since it cannot explain any causal correlation with the labels. \n",
    "Overall, the sparsity of the features tells us that we'll need to extract as much information as we can from graph structure. \n",
    "As far as labels are concerned, under the assumption of independence between label classes,\n",
    "for the Central Limit Theorem we can conclude that the means of the elements belonging to each one of the 122 classes \n",
    "will be the same between training and test set. ( this will come in handy at the end )\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils  \n",
    "from node2vec import Node2Vec  # NODE2VEC EMBEDDINGS \n",
    "import classifier as clf  # VERTEX CLASSIFIER\n",
    "import matplotlib.pyplot as plt  # PLOTTING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## LOADING THE DATA\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "<font size=\"3\">In the following section we define four foundamental matrices:</font>\n",
    "<ul>\n",
    "    <li>$X_{train}\\in \\{0,1\\}^{n_{train}\\times49}$</li>\n",
    "    <br>\n",
    "    <li>$X_{test}\\in \\{0,1\\}^{n_{test}\\times49}$ </li>\n",
    "    <br>\n",
    "    <li>$X = \\begin{bmatrix}X_{train} \\\\ X_{test}\\end{bmatrix} \\in \\{0,1\\}^{n\\times49}$</li>\n",
    "    <br>\n",
    "    <li>$L\\in \\{0,1\\}^{n\\times122}$ \n",
    " </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATA\n",
    "vertices_train, vertices_test = utils.build_vertices()\n",
    "\n",
    "X_train_df = utils.build_dataframe(vertices_train, \"feature\")\n",
    "X_train_df = X_train_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "X_test_df = utils.build_dataframe(vertices_test, \"feature\")\n",
    "X_test_df = X_test_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "labels_df = utils.build_dataframe(vertices_train, \"label\", preserve_int_col_name=True)\n",
    "\n",
    "\n",
    "# BUILDING NUMPY MATRICES \n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "labels = labels_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size=\"3\">Here we define our graph  $\\space G = (V,E)\\space$ that represents the PPI network and we explicit all the edges.</font>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<div>\n",
    "<font size=\"3\">Then we build our masks for training and test set : </font>\n",
    "<ul>\n",
    "    <li>$idx_{train} =  \\begin{pmatrix} 0,1\\dots44905 \\end{pmatrix} $</li>\n",
    "    <br>\n",
    "    <li>$idx_{test} = \\begin{pmatrix} 44906,44907\\dots56943 \\end{pmatrix} $ </li>\n",
    "    <br>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK FOR TRAIN/TEST\n",
    "train_idx = range(X_train.shape[0])\n",
    "test_idx = range(X_train.shape[0],X.shape[0])\n",
    "\n",
    "# BUILDING THE GRAPH\n",
    "G = utils.build_graph()\n",
    "G = G.to_directed()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## NODE2VEC\n",
    "\n",
    "\n",
    "In our first approach we ignore the features matrix $\\space X \\space$, instead we embed the vertexes with Node2Vec algorithm, using a definition of neighborhood as flexible as possible.\n",
    "\n",
    "$ Node2Vec(G) \\mapsto R^{128} \\space$ \n",
    "\n",
    "For every source node $u\\in V$ , we define $\\space N_{s}(u) \\subset V\\space$  as a network neighborhood of node $u$ generated through a neighborhood sampling strategy $S$\n",
    "The strategy $S$ of Node2Vec is the following.\n",
    "Given a source node $\\space u\\space$, we simulate a random walk of fixed length $\\space l\\space$. Let $\\space c_{i}$ denote the $\\space i_{th}\\space$ node in the walk, starting with $c_{0} = u\\space$. Nodes $\\space c_{i} \\space$ are generated with the following distribution: $\\space P(c_{i} = x \\mid c_{i-1}=v)  =   \\begin{cases} \n",
    "      \\frac{\\pi_{vx}}{Z} & if \\space(v,x) \\in E \\\\\n",
    "      0 & otherwise\n",
    "   \\end{cases}\n",
    "$\n",
    "where $\\space \\pi_{vx} \\space$ is the unnormalized transition probability between nodes $\\space v \\space$ and $\\space x \\space$, and $\\space Z \\space$ is the normalizing constant. \n",
    "\n",
    "Consider a random walk that just traversed\n",
    "edge $(t, v)$ and now resides at node $v$. The walk now needs to decide on the next step so it evaluates the transition probabilities $\\pi_{vx}$ on edges $(v, x)$ leading from $v$. We set then the unnormalized transition probability to $\\space \\pi_{vx} =\\alpha_{pq}(t, x)\\cdot w_{vx}$, where, $\\space \\alpha_{pq}(t, x) =  \\begin{cases} \n",
    "      \\frac{1}{p} & if \\space d_{tx}=0 \\\\\n",
    "       1 & if \\space d_{tx}=1 \\\\\n",
    "      \\frac{1}{q} & if \\space d_{tx}=2\n",
    "   \\end{cases}\\space\n",
    "$ and in our graph $\\space w = 1 \\space$ since the edges are unweighted. \n",
    "\n",
    "The use of two parameters $\\space p \\space$ and $\\space q \\space$ allowed us to combine in a single path breadth-first sampling and depth-first sampling. In particular the return parameter $\\space p \\space$  controls the likelihood of immediately revisiting a node in the walk, and the in-out parameters 'q' allowes the search to differentiate between \"inward\" and \"outward\"nodes. Here we set $\\space p = 1 \\space$  and $\\space q =5 \\space$  biasing the walks close to node $\\space t \\space$ (BFS) in order to emphasize structural equivalence.\n",
    "<div align=center>\n",
    "<img  src=\"./images/node2vec.jpg\" height=280 width=280>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING WALKS OVER THE GRAPH\n",
    "node2vec = Node2Vec(G, dimensions=128, walk_length=12, num_walks=10, p=1, q=5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### SKIP-GRAM \n",
    "\n",
    "We proceed by applying the Skip-gram model. We seek to optimize the following objective function, which maximizes the log-probability of observing a network neighborhood $\\space N_{S}(u)\\space$ for a node u conditioned on its feature representation, given by f: \n",
    "\n",
    "$$\n",
    " \\max_{f} \\sum_{u \\in V} \\log P(N_{s}(u)\\mid f(u)) $$\n",
    "\n",
    "In order to make the optimization problem solvable we make two standard assumptions:\n",
    "\n",
    "• Conditional independence. We factorize the likelihood by assuming that the probability of observing a neighborhood node given the embedding representation of the source node is independent of  any other neighborhood node:\n",
    "\n",
    "$$ P(N_{s}(u)\\mid f(u)) = \\prod_{n_{i} \\in N_{s}(u)}P(n_{i} \\mid f(u)) $$\n",
    "\n",
    "\n",
    "• Symmetry in feature space. A source node and neighborhood node have a symmetric effect over each other in feature space. Accordingly, we model the conditional likelihood of every source-neighborhood node pair as a softmax unit parametrized by a dot product of their embeddings:\n",
    "\n",
    "$$P(n_{i} \\mid f(u)) = \\frac{\\exp(\\space f(n_{i}) \\cdot f(u))}{\\sum_{v \\in V}\\exp(f(v) \\cdot f(u)} $$\n",
    "\n",
    "\n",
    "With the above assumptions, the objective function simplifies to:\n",
    "\n",
    "$$ \\max_{f} \\sum_{u \\in V}\\bigg[-\\log Z_{u} + \\sum_{n_{i} \\in N_{s}(u)}f(n_{i} \\cdot f(u)\\bigg]$$\n",
    "\n",
    "which is a simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING THE SKIP-GRAM MODEL\n",
    "skipgram = node2vec.fit(window=8)\n",
    "\n",
    "\n",
    "#  SAVING OUR EMBEDDINGS\n",
    "embedding_n2v = skipgram[skipgram.wv.vocab]   \n",
    "np.save('./embedding/embedding_n2v.npy', embedding_n2v)  # SAVING AS  A .NPY FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPIEGA CHE CONCATENIAMO FEATURES CON EMBEDDING PER CLASSIFICARE, ACCENNO SULLA TRAIN ACCURACY (?), ACCENNO AL FATTO CHE NEL CLASSIFIER BILANCIAMO I PESI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.438\n",
      "\tAccuracy, exact matches: 0.000\n",
      "\tMacro F1 Score: 0.439\n",
      "\tMicro F1 Score: 0.470\n"
     ]
    }
   ],
   "source": [
    "# X MATRIX FOR CLASSIFICATION\n",
    "train_embedding_n2v = embedding_n2v[train_idx]  # EXTRACTING TRAINING SET EMBEDDINGS\n",
    "test_embedding_n2v = embedding_n2v[test_idx]  #  EXTRACTING TEST SET EMBEDDING\n",
    "X_train_n2v = np.concatenate((X_train, train_embedding_n2v), axis=1)  #  FEATURES + EMBEDDING\n",
    "X_test_n2v = np.concatenate((X_test, test_embedding_n2v), axis=1)  # FEATURES + EMBEDDINGS\n",
    "\n",
    "\n",
    "#  TESTING VALIDATION ACCURACY\n",
    "#clf.validation_accuracy(X_train_n2v, labels)\n",
    "\n",
    "#  TESTING TRAIN ACCURACY\n",
    "node2vec_model = clf.fit_model(X_train_n2v, labels)  # RETURNS TRAINED MODEL AND TRAIN ACCURACY\n",
    "\n",
    "\n",
    "#  MAKING PREDICTIONS\n",
    "node2vec_pred = node2vec_model.predict_proba(X_test_n2v) > 0.4  # EVALUATING PREDICTIONS\n",
    "utils.get_results('./results/node2vec_pred.csv',node2vec_pred, X_test_df)  # SAVING RESULTS IN A .CSV FOR KAGGLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTO SUI RISULTATI OTTENUTI CON NODE2VEC, !!INTRODUZIONE AL PROSSIMO APPROCCIO( GCN ) \n",
    ", SBIZZARRISCITI..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gcn.model import GCN \n",
    "from train  import train_model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETRO  LAMDA PER GLI AUTOANELLI , SPIEGA COME VIENE CREATA LA MATRICE ( DAI UN OCCHIO ALLA FUNZIONE IN UTILS.PY ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING ADJ MATRIX FOR GCN\n",
    "A = utils.adjacency_matrix_GCN(G, 1)  \n",
    "\n",
    "\n",
    "# DEFINING OUR PARAMETERS\n",
    "n_features = X.shape[1]\n",
    "n_classes = labels.shape[1]\n",
    "n_hidden = 32  #  NUMBER OF HIDDEN PARAMETERS IN OUR NET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUI VIENE CREATO E ALLENATO IL MODELLO..MAGARI UN BREVE ACCENNO ALLA STUTTURA ( 2 LAYER, HIDDEN PARAMETERS,DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [00:48<00:07,  1.09s/it]"
     ]
    }
   ],
   "source": [
    "# CREATING AND TRAINING OUR MODEL\n",
    "\n",
    "gcn_model = GCN(n_features, n_hidden, n_classes, dropout=0.5)\n",
    "embedding_gcn = train_model(gcn_model, X, A, labels, train_idx, epochs=50, lr=0.005, wd=5e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.710\n",
      "\tAccuracy, exact matches: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMacro F1 Score: 0.195\n",
      "\tMicro F1 Score: 0.506\n"
     ]
    }
   ],
   "source": [
    "#  EXTRACTING EMBEDDINGS \n",
    "train_embedding_gcn = embedding_gcn[train_idx]\n",
    "test_embedding_gcn = embedding_gcn[test_idx]\n",
    "\n",
    "\n",
    "#  TESTING TRAIN ACCURACY (SIGMOID TRESHOLD SET AT 0.4 )\n",
    "gcn_train_pred = torch.sigmoid(train_embedding_gcn).detach().numpy() > 0.4 \n",
    "utils.get_score(gcn_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_gcn.npy', embedding_gcn.detach().numpy())  # .NPY FILE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTO SUI RISULTATI OTTENUTI ( TRAINING ACCURACY ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "gcn_test_pred = torch.sigmoid(test_embedding_gcn).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "gcn_test_pred = utils.a_third_law(labels,gcn_test_pred) # 0.475 accuracy\n",
    "utils.get_results('./results/gcn_pred.csv',gcn_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONI FINALI SULLA GCN ( ACCURACY PRATICAMENTE UGUALE A NODE2VEC SE NON INFERIORE ) ( LE FEATURE NON SERVONO A NULLA??) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASSIAMO AL PROSSIMO APPROCCIO.. SAGE ( SBIZZARRISCITI )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.model import SAGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STRUTTURA DEL MODELLO UGUALE A GCN ( 2LAYER , HIDDEN PARAMETERS..) SCRIVI QUELLO CHE PREFERISCI.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [04:31<00:00, 10.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tHamming accuracy: 0.306\n",
      "\tAccuracy, exact matches: 0.000\n",
      "\tMacro F1 Score: 0.445\n",
      "\tMicro F1 Score: 0.468\n"
     ]
    }
   ],
   "source": [
    "#  CREATING THE MODEL\n",
    "edge_list = torch.LongTensor(utils.edge_list_SAGE())  # list of all the edges\n",
    "sage_model = SAGE(n_features, n_hidden, n_classes, 0.5)\n",
    "\n",
    "\n",
    "#  TRAINING THE MODEL \n",
    "embedding_sage = train_model(sage_model, X, edge_list, labels, train_idx, epochs=25, lr=0.1,wd=5e-3)\n",
    "sage_train_pred = torch.sigmoid(embedding_sage[train_idx]).detach().numpy() > 0.5# TRESHOLD ON SIGMOID PROBABILITIES\n",
    "sage_train_pred = utils.a_third_law(labels,sage_test_pred)\n",
    "utils.get_score(sage_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_sage.npy', embedding_sage.detach().numpy())  # .NPY FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "sage_test_pred = torch.sigmoid(embedding_sage[test_idx]).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "sage_test_pred = utils.a_third_law(labels,sage_test_pred) # BEST SAGE 0.477\n",
    "utils.get_results('./results/sage_test_pred.csv',sage_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSIONI RAGGIUNTE SU SAGE.. ( NODE2VEC-GCN-SAGE TUTTI CIRCA LA  STESSA ACCURACY CIRCA 0.44/0.45/0.46 SUL TEST ) INIZIAMO A SOSPETTARE QUALCOSA(??) \n",
    "PROVIAMO A GIOCARE UN PO CON CONCATENAZIONE DEGLI EMBEDDING E PCA (?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=16.7min\n",
      "[CV] ................................................. , total=17.4min\n",
      "[CV] ................................................. , total=17.5min\n",
      "[CV] ................................................. , total=17.6min\n",
      "[CV] ................................................. , total=17.6min\n",
      "[CV] ................................................. , total=17.7min\n",
      "[CV] ................................................. , total=17.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done   7 out of  10 | elapsed: 17.8min remaining:  7.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=17.8min\n",
      "[CV] ................................................. , total=17.8min\n",
      "[CV] ................................................. , total=17.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done  10 out of  10 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crossvalidation Micro-F1: 0.425\n"
     ]
    }
   ],
   "source": [
    "Y = np.concatenate((embedding_n2v,embedding_sage),axis=1)  # N2V EMBEDDING concatenated SAGE EMBEDDING\n",
    "clf.validation_accuracy(Y[train_idx],labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RISULTATI UN PO DELUDENTI ( 0.425 DI MICRO ) PER LA CROSS VALIDATION (SAGE+N2V) CI ASPETTAVAMO DI MEGLIO... VALE LO STESSO PER GCN+N2V ( OMETTO PER BREVITA').\n",
    "\n",
    "PROVIAMO ORA CON UNA PCA SULLA CONCATENAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance:  0.9977764\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total= 4.0min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done   7 out of  10 | elapsed:  4.1min remaining:  1.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n",
      "[CV] ................................................. , total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Done  10 out of  10 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean crossvalidation Micro-F1: 0.427\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 64)\n",
    "Y_pca = pca.fit_transform(Y)  #  250 --> 64\n",
    "print('Explained variance: ',np.sum(pca.explained_variance_ratio_))  #  GOOD EXPLAINED VARIANCE\n",
    "clf.validation_accuracy(Y_pca[train_idx],labels)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALTRO RISULTATO ABBASTANZA DELUDENTE.. PROVA A COMMENTARE TU ( NON C'E' VERSO DI MIGLIORARLA STA ACCURACY )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PASSIAMO ORA ALLA NOSTRA ULTIMA SPERANZA.. GAT ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gat.ppi import PPI\n",
    "from gat.model import GAT\n",
    "from gat.training import train,test\n",
    "from torch_geometric.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOADING DATASETS \n",
    "train_dataset = PPI('./gat',split='train')\n",
    "test_dataset = PPI('./gat',split='test')\n",
    "valid_dataset = PPI('./gat',split='valid')  #  LET'S KEEP SOME TRAINING SAMPLES FOR VALIDATION..\n",
    "\n",
    "\n",
    "#  BATCH TRAINING.. \n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIZIONE DEL MODELLO GAT USATO DA NOI.. FAI RIFERIMENTO AL PAPER OPPURE AL FILE MODEL.PY IN /GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 0.7536, Acc: 0.4226\n",
      "Epoch: 02, Loss: 0.6801, Acc: 0.3810\n",
      "Epoch: 03, Loss: 0.6832, Acc: 0.3790\n",
      "Epoch: 04, Loss: 0.6222, Acc: 0.4400\n",
      "Epoch: 05, Loss: 0.6156, Acc: 0.4468\n",
      "Epoch: 06, Loss: 0.6720, Acc: 0.4529\n",
      "Epoch: 07, Loss: 0.7165, Acc: 0.4633\n",
      "Epoch: 08, Loss: 0.6544, Acc: 0.4316\n",
      "Epoch: 09, Loss: 0.6289, Acc: 0.4537\n",
      "Epoch: 10, Loss: 0.6482, Acc: 0.4421\n",
      "Epoch: 11, Loss: 0.5713, Acc: 0.4239\n",
      "Epoch: 12, Loss: 0.6068, Acc: 0.4197\n",
      "Epoch: 13, Loss: 0.8002, Acc: 0.4168\n",
      "Epoch: 14, Loss: 0.8466, Acc: 0.4613\n",
      "Epoch: 15, Loss: 0.6561, Acc: 0.4474\n",
      "Epoch: 16, Loss: 0.5970, Acc: 0.4179\n",
      "Epoch: 17, Loss: 0.6979, Acc: 0.4191\n",
      "Epoch: 18, Loss: 0.7053, Acc: 0.4709\n",
      "Epoch: 19, Loss: 0.5955, Acc: 0.4533\n",
      "Epoch: 20, Loss: 0.5896, Acc: 0.4917\n",
      "Epoch: 21, Loss: 0.6104, Acc: 0.4518\n",
      "Epoch: 22, Loss: 0.7435, Acc: 0.4291\n",
      "Epoch: 23, Loss: 0.6718, Acc: 0.5027\n",
      "Epoch: 24, Loss: 0.5976, Acc: 0.4605\n",
      "Epoch: 25, Loss: 0.5660, Acc: 0.4668\n",
      "Epoch: 26, Loss: 0.5587, Acc: 0.4756\n",
      "Epoch: 27, Loss: 0.5985, Acc: 0.4859\n",
      "Epoch: 28, Loss: 0.6049, Acc: 0.4964\n",
      "Epoch: 29, Loss: 0.5814, Acc: 0.4835\n",
      "Epoch: 30, Loss: 0.5703, Acc: 0.5060\n",
      "Epoch: 31, Loss: 0.5568, Acc: 0.5194\n",
      "Epoch: 32, Loss: 0.5420, Acc: 0.4867\n",
      "Epoch: 33, Loss: 0.5490, Acc: 0.4968\n",
      "Epoch: 34, Loss: 0.5573, Acc: 0.4900\n",
      "Epoch: 35, Loss: 0.5566, Acc: 0.5097\n",
      "Epoch: 36, Loss: 0.5372, Acc: 0.5158\n",
      "Epoch: 37, Loss: 0.5221, Acc: 0.5232\n",
      "Epoch: 38, Loss: 0.5101, Acc: 0.5001\n",
      "Epoch: 39, Loss: 0.5207, Acc: 0.5320\n",
      "Epoch: 40, Loss: 0.5398, Acc: 0.4999\n",
      "Epoch: 41, Loss: 0.5250, Acc: 0.5340\n",
      "Epoch: 42, Loss: 0.5172, Acc: 0.5219\n",
      "Epoch: 43, Loss: 0.5039, Acc: 0.5086\n",
      "Epoch: 44, Loss: 0.5031, Acc: 0.5159\n",
      "Epoch: 45, Loss: 0.5110, Acc: 0.5202\n",
      "Epoch: 46, Loss: 0.5103, Acc: 0.4871\n",
      "Epoch: 47, Loss: 0.5009, Acc: 0.5368\n",
      "Epoch: 48, Loss: 0.5017, Acc: 0.5323\n",
      "Epoch: 49, Loss: 0.4986, Acc: 0.5352\n",
      "Epoch: 50, Loss: 0.5082, Acc: 0.5372\n",
      "Epoch: 51, Loss: 0.4926, Acc: 0.5259\n",
      "Epoch: 52, Loss: 0.4970, Acc: 0.5200\n",
      "Epoch: 53, Loss: 0.5053, Acc: 0.5249\n",
      "Epoch: 54, Loss: 0.5012, Acc: 0.5278\n",
      "Epoch: 55, Loss: 0.5279, Acc: 0.5377\n",
      "Epoch: 56, Loss: 0.5755, Acc: 0.5313\n",
      "Epoch: 57, Loss: 0.5766, Acc: 0.5245\n",
      "Epoch: 58, Loss: 0.5226, Acc: 0.5181\n",
      "Epoch: 59, Loss: 0.5033, Acc: 0.5264\n"
     ]
    }
   ],
   "source": [
    "#  BUILDING AND TRAINING OUR MODEL\n",
    "model = GAT(n_features,n_classes)\n",
    "for epoch in range(1, 60):\n",
    "    loss = train(model,train_loader) \n",
    "    acc = test(model,valid_loader) \n",
    "    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING PREDICTIONS\n",
    "model.cpu()\n",
    "for data in test_loader:    \n",
    "    out = model(data.x,data.edge_index)\n",
    "    \n",
    "pred = out.float().cpu() > 0\n",
    "pred = utils.a_third_law(labels,pred)\n",
    "\n",
    "utils.get_results('./results/gat_pred.csv',pred, X_test_df)  # SAVING RESULTS IN A .CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENTIAMO I RISULTATI OTTENUTI.. 0.52  BEST SCORE ( ABBIAMO USATO UN PO DI STATISTICA PER AIUTARCI )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPROCCIAMO IL METODO STATISTICO.. SPIEGA UN PO LMEAN E COSA ANDIAMO A FARE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmean = utils.get_lmean(labels)    \n",
    "lmean = utils.sort_lmean(lmean)  #  DESCENDING ORDER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPIEGA L'ALGORITMO.. UN PO DI FORMULE FANNO BENE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0\n",
    "k = 0\n",
    "f1_values = np.zeros(lmean.shape[0])\n",
    "for i in range(lmean.shape[0]):\n",
    "    k += lmean[i][0]\n",
    "for s in range(lmean.shape[0]):\n",
    "    A += lmean[s][0]\n",
    "    f1 = 2 * A / (k+ntr*(s+1))\n",
    "    f1_values[s] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f85e9658c18>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(f1_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lmean_f[:np.argmax(f1_values),1]\n",
    "pred = np.zeros((X_test.shape[0],labels.shape[1]))\n",
    "\n",
    "for col in range(labels.shape[1]):\n",
    "    for i in range(np.argmax(f1_values)):\n",
    "        if(mask[i] == col):\n",
    "            pred[:,col] =1 \n",
    "            \n",
    "utils.get_results('./results/stat.csv',pred, X_test_df)  # SAVING RESULTS IN A .CSV  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
